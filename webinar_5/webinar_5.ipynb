{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5f613a-034c-43c4-bbba-40a70d0b710f",
   "metadata": {},
   "source": [
    "# ДЗ по \"Введение в нейронные сети (Вебинар)\"\n",
    "\n",
    "## Вебинар 5. Рекуррентные нейронные сети \n",
    "* Домашнее задание:  \n",
    "1. Попробуйте починить сеть по словам.  \r\n",
    "2. Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно \r\n",
    "более осмысленного текста. Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия. \r\n",
    "Можно использовать текст другого произведения  \r\n",
    "\r\n",
    "Сдавать как обычно гитхабом или гугл колабом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439d14d0-fbed-457b-b114-b1becb38c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем пакеты в окружение, если они не установлены\n",
    "# !pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a8d7d84-f667-4155-9b18-b8fd0b56138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, SimpleRNN, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4921371-6a52-450e-b5bc-1da800b21e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "EPOCH = 100 # Количество эпох в модели обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cc6ff-42e6-407e-88bf-9c7eb1c23064",
   "metadata": {},
   "source": [
    "## Прогнозируем символы  \n",
    "\n",
    "ссылка на материал - https://proproprogs.ru/neural_network/kak-rekurrentnaya-neyronnaya-set-prognoziruet-simvoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1f5f2c-1c62-478e-a8d8-ec2616ed5f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И, чтобы было проще решать эту задачу, оставим в тексте только символы русских букв и символы пробела:\n",
    "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\ufeff', '')   # убираем первый невидимый символ\n",
    "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb013274-3e6b-4798-849e-2f34f2dec030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83bb78bd-be0f-47fc-abbe-4dd95f609668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# То есть, всего у нас будет 34 разных символа:\n",
    "num_characters = 34  # 33 буквы + пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88874218-4282-449c-873d-bd10d0afbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы им воспользоваться, сначала нужно создать экземпляр класса Tokenizer, который имеет следующие важные параметры:\n",
    "\n",
    "# num_words – максимальное количество слов (символов), которое вернет Tokenizer (если элементов будет больше, \n",
    "# то останутся наиболее повторяющиеся в тексте);\n",
    "# filters – исключаемые из текста символы (по умолчанию, следующие: !–»—#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n\\r);\n",
    "# lower = True – автоматический перевод в нижний регистр для единообразия больших и малых символов;\n",
    "# split = '  ' – разделение слов по символу пробела;\n",
    "# char_level=False – если False, то текст делится на слова, иначе – на символы.\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dbb5152-126d-4d4f-917f-a3ef9811b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И пропустим через него загруженный текст\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38630e7b-3e83-4938-8c91-180173f486e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
     ]
    }
   ],
   "source": [
    "# В итоге, формируется словарь:\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d97131-71e3-490d-8101-f78d48c55812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее, преобразуем текст в набор OHE-векторов:\n",
    "inp_chars = 4 # Число первых символов\n",
    "data = tokenizer.texts_to_matrix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd01b43b-0a87-4601-a2de-c045efcd0304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b331694-30b7-4aa3-92c2-705e38c37e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для начала вычислим размер обучающего множества:\n",
    "n = data.shape[0]-inp_chars\n",
    "n  #размер обучающего множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4daaa9ef-77f0-421a-aa99-4664572be6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И, далее, сформируем входной тензор и прогнозные значения:\n",
    "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
    "Y = data[inp_chars:] #предсказание следующего символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dc045f5-6c4d-465b-bd30-386fb6f10365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 500)               267500    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 34)                17034     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 284,534\n",
      "Trainable params: 284,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Отлично, данные для обучения готовы. Теперь создадим рекуррентную НС с помощью Keras\n",
    "model = Sequential()\n",
    "model.add(Input((inp_chars, num_characters)))\n",
    "model.add(SimpleRNN(500, activation='tanh'))\n",
    "model.add(Dense(num_characters, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02763be5-8919-4bfd-85ad-c4346541ec91",
   "metadata": {},
   "source": [
    "### Создаём callback EarlyStopping (защита от переобучения)\n",
    "см. [ссылка ToTube](https://www.youtube.com/watch?v=aiH_oXtuzjE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4fa349-6c43-4fb9-b25d-67769a79645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Настраиваем защиту от переобучения\n",
    "erly_stoping_callback = EarlyStopping(monitor='accuracy', patience=3)  # Если метрика 'val_accuracy' продолжает снижение два шага подряд,\n",
    "                                                                           # то выходим из процесса обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b399b09e-9ee4-4309-82b1-c1e58cf37075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 3.4506 - accuracy: 0.0597\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 2.6368 - accuracy: 0.2886\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 2.2354 - accuracy: 0.3532\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.9478 - accuracy: 0.4677\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.6363 - accuracy: 0.5025\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4219 - accuracy: 0.5473\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2738 - accuracy: 0.5970\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1126 - accuracy: 0.6965\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0850 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9354 - accuracy: 0.6965\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9039 - accuracy: 0.7313\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8183 - accuracy: 0.7711\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.7662\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.8159\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.8408\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.8060\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.8458\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.8358\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.8706\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8408\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.8657\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.8806\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8706\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.8358\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.8458\n"
     ]
    }
   ],
   "source": [
    "# Компилируем и обучаем модель НС\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "history = model.fit(X, Y, batch_size=32, epochs=EPOCH,  callbacks=[erly_stoping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e860dcb-ef01-4290-a6de-27dbcd768988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение остановлено на эпохе 24\n"
     ]
    }
   ],
   "source": [
    "if erly_stoping_callback.stopped_epoch >=1:\n",
    "    print('Обучение остановлено на эпохе', erly_stoping_callback.stopped_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc16729d-bcb0-42fd-9584-a56fdfc33690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее, объявим вспомогательную функцию, в которой будет выполняться прогноз очередного символа и добавления его в конец начальной строки:\n",
    "def buildPhrase(inp_str, str_len = 50):\n",
    "  for i in range(str_len):\n",
    "    x = []\n",
    "    for j in range(i, i+inp_chars):\n",
    "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
    "\n",
    "    x = np.array(x)\n",
    "    inp = x.reshape(1, inp_chars, num_characters)\n",
    "    print(f'{inp_chars = }')\n",
    "    print(f'{num_characters = }')\n",
    "    print(f'{inp.shape = }')\n",
    "    \n",
    "\n",
    "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
    "\n",
    "    inp_str += d # дописываем строку\n",
    "\n",
    "  return inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a46e5d3-323b-4eb9-9238-a111aa450dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "inp_chars = 4\n",
      "num_characters = 34\n",
      "inp.shape = (1, 4, 34)\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# Ей на вход подается начальная строка длиной inp_chars символов и, затем, она подается на НС и прогнозируется следующий символ. Далее, \n",
    "# мы используем это прогнозное значение и получаем следующее и так далее делаем str_len раз.\n",
    "res = buildPhrase(\"лучш\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c53a2817-2e07-4646-af30-5927052ad864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лучший отвеч извеьликвыорле в свою способломыикотнрче \n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60ea19-de9e-4517-88d8-bcedcef3e4a9",
   "metadata": {},
   "source": [
    "## Делаем прогноз слов рекуррентной сетью Embedding слой\n",
    "\n",
    "Ссылка на материал - https://proproprogs.ru/neural_network/delaem-prognoz-slov-rekurrentnoy-setyu-embedding-sloy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1416b6-3421-486f-a0c8-4aeb9b2a936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим текст\n",
    "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый симво"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce23d8c-f07e-4c1e-b984-f44b6fbda0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь нам нужно разбить эти высказывания на слова. Для этого воспользуемся уже знакомым из прошлого занятия инструментом Tokenizer и \n",
    "# положим, что максимальное число слов будет равно 1000:\n",
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                       lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c9d8227-f674-4e61-ac42-7ca9d8258e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Итак, мы разбили текст на слова и для примера выведем их начальный список:\n",
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e20a46-99d8-4007-81ba-34f64fd7d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее, мы преобразуем текст в последовательность чисел в соответствии с полученным словарем. \n",
    "# Для этого используется специальный метод класса Tokenizer:\n",
    "data = tokenizer.texts_to_sequences([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f3af654-9b33-44c8-b225-e92c8f3b76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Осталось закодировать числа массива data в one-hot векторы. Для этого мы воспользуемся методом to_categorical пакета Keras:\n",
    "res = to_categorical(data[0], num_classes=maxWordsCount)\n",
    "print( res.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be5db14d-2189-402b-b6d4-2cefb6aeb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Затем, из этой матрицы сформируем тензор обучающей выборки и соответствующий набор выходных значений. \n",
    "# Для начала вычислим размер обучающего множества:\n",
    "inp_words = 3\n",
    "n = res.shape[0]-inp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebe7d33f-75ca-442a-bf7f-e944f9734c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И, далее, сформируем входной тензор и прогнозные значения также, как мы это делали с символами:\n",
    "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
    "Y = res[inp_words:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5dde419-3b1a-475e-9fa9-745364ba6b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               144512    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              129000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,512\n",
      "Trainable params: 273,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Все, у нас есть обучающая выборка и требуемые выходные значения. Осталось создать модель рекуррентной сети. \n",
    "# Мы ее возьмем из предыдущего занятия с числом нейронов скрытого слоя 128 и maxWordsCount нейронами на выходе с функцией активации softmax:\n",
    "model_2 = Sequential()\n",
    "model_2.add(Input((inp_words, maxWordsCount)))\n",
    "model_2.add(SimpleRNN(128, activation='tanh'))\n",
    "model_2.add(Dense(maxWordsCount, activation='softmax'))\n",
    "model_2.summary()\n",
    " \n",
    "model_2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb28e78a-aabb-441f-8d17-25074e95d76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 6.9059 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8802 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8543 - accuracy: 0.0714\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8280 - accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.8010 - accuracy: 0.4643\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 6.7732 - accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7441 - accuracy: 0.8214\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7134 - accuracy: 0.9286\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6809 - accuracy: 0.9643\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6461 - accuracy: 0.9643\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6087 - accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5680 - accuracy: 0.9643\n"
     ]
    }
   ],
   "source": [
    "# Готово. Запускаем процесс обучения:\n",
    "history_2 = model_2.fit(X, Y, batch_size=32, epochs=EPOCH, callbacks=[erly_stoping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a454acd-0d58-4c84-baf1-72e49cc63e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение остановлено на эпохе 11\n"
     ]
    }
   ],
   "source": [
    "# Смотрим на какой эпохе остановилось обучение\n",
    "if erly_stoping_callback.stopped_epoch >=1:\n",
    "    print('Обучение остановлено на эпохе', erly_stoping_callback.stopped_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43778195-918a-489d-a48d-0e34bb1acd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# И давайте теперь посмотрим, что у нас получилось. Запишем функцию для формирования текста из спрогнозированных слов:\n",
    "def buildPhrase_2(texts, str_len = 20):\n",
    "  res = texts\n",
    "  data = tokenizer.texts_to_sequences([texts])[0]\n",
    "  print(f'{len(data) = }')\n",
    "  for i in range(str_len):\n",
    "    x = to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
    "    print(f'{x.shape = }')\n",
    "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
    " \n",
    "    pred = model_2.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    indx = pred.argmax(axis=1)[0]\n",
    "    data.append(indx)\n",
    " \n",
    "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
    " \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "291f51ae-3baf-4581-bcf2-bc3dcd0720cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 3\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "x.shape = (3, 1000)\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# И вызовем ее с тремя первыми словами\n",
    "res = buildPhrase_2('лучший ответ на')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97046beb-329e-4390-811d-270e177d75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "лучший ответ на проблемы которые возникли в понедельник думайте позитивно и верьте в свою способность достигать отличных результатов если вы смогли в понедельник\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1fad17-4a7c-4efa-b067-4e646c8dd899",
   "metadata": {},
   "source": [
    "## Вывод:\n",
    "### Выполнив данное ДЗ, на практике посмотрел как предсказываются последующие буквы и слова с помощью рекурентных НС."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
