{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "218f8066",
   "metadata": {},
   "source": [
    "# ДЗ по \"Введение в нейронные сети (Вебинар)\"\n",
    "\n",
    "## Вебинар 1. Основы обучения нейронных сетей \n",
    "* ДЗ от преподавателя:  \n",
    "Доделать НС с урока, добавить метод predict и проверить на своих собственных данных, \n",
    "оценить accuracy.  \n",
    "Как вариант, опционально кто сможет для решения этих входных данных обучите НС mlpclassifier \n",
    "от sklearn.  \n",
    "Сдача только через гитхаб либо ссылкой на блокнот Google Colab.\n",
    "\n",
    "### Часть 1. Доделываем НС с урока добавляем метод predict и проверяем на своих собственных данных, оцениваем accuracy. \n",
    "\n",
    "Делаем как тут - https://proglib.io/p/pishem-neyroset-na-python-s-nulya-2020-10-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386c5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  # Наша функция активации: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "  def __init__(self, weights, bias):\n",
    "    self.weights = weights\n",
    "    self.bias = bias\n",
    "\n",
    "  def feedforward(self, inputs):\n",
    "    # Умножаем входы на веса, прибавляем порог, затем используем функцию активации\n",
    "    total = np.dot(self.weights, inputs) + self.bias\n",
    "    return sigmoid(total)\n",
    "\n",
    "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
    "bias = 4                   # b = 4\n",
    "n = Neuron(weights, bias)\n",
    "\n",
    "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
    "print(n.feedforward(x))    # 0.9990889488055994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4d0291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  Нейронная сеть с:\n",
    "    - 2 входами\n",
    "    - скрытым слоем с 2 нейронами (h1, h2)\n",
    "    - выходным слоем с 1 нейроном (o1)\n",
    "  Все нейроны имеют одинаковые веса и пороги:\n",
    "    - w = [0, 1]\n",
    "    - b = 0\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    weights = np.array([0, 1])\n",
    "    bias = 0\n",
    "\n",
    "    # Используем класс Neuron из предыдущего раздела\n",
    "    self.h1 = Neuron(weights, bias)\n",
    "    self.h2 = Neuron(weights, bias)\n",
    "    self.o1 = Neuron(weights, bias)\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    out_h1 = self.h1.feedforward(x)\n",
    "    out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "    # Входы для o1 - это выходы h1 и h2\n",
    "    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "\n",
    "    return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x)) # 0.7216325609518421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f487bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true и y_pred - массивы numpy одинаковой длины.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "y_true = np.array([1, 0, 0, 1])\n",
    "y_pred = np.array([0, 0, 0, 0])\n",
    "\n",
    "print(mse_loss(y_true, y_pred)) # 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1751f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.228\n",
      "Epoch 10 loss: 0.151\n",
      "Epoch 20 loss: 0.106\n",
      "Epoch 30 loss: 0.079\n",
      "Epoch 40 loss: 0.061\n",
      "Epoch 50 loss: 0.049\n",
      "Epoch 60 loss: 0.040\n",
      "Epoch 70 loss: 0.034\n",
      "Epoch 80 loss: 0.029\n",
      "Epoch 90 loss: 0.025\n",
      "Epoch 100 loss: 0.022\n",
      "Epoch 110 loss: 0.020\n",
      "Epoch 120 loss: 0.018\n",
      "Epoch 130 loss: 0.016\n",
      "Epoch 140 loss: 0.015\n",
      "Epoch 150 loss: 0.014\n",
      "Epoch 160 loss: 0.013\n",
      "Epoch 170 loss: 0.012\n",
      "Epoch 180 loss: 0.011\n",
      "Epoch 190 loss: 0.010\n",
      "Epoch 200 loss: 0.010\n",
      "Epoch 210 loss: 0.009\n",
      "Epoch 220 loss: 0.009\n",
      "Epoch 230 loss: 0.008\n",
      "Epoch 240 loss: 0.008\n",
      "Epoch 250 loss: 0.007\n",
      "Epoch 260 loss: 0.007\n",
      "Epoch 270 loss: 0.007\n",
      "Epoch 280 loss: 0.006\n",
      "Epoch 290 loss: 0.006\n",
      "Epoch 300 loss: 0.006\n",
      "Epoch 310 loss: 0.006\n",
      "Epoch 320 loss: 0.005\n",
      "Epoch 330 loss: 0.005\n",
      "Epoch 340 loss: 0.005\n",
      "Epoch 350 loss: 0.005\n",
      "Epoch 360 loss: 0.005\n",
      "Epoch 370 loss: 0.005\n",
      "Epoch 380 loss: 0.004\n",
      "Epoch 390 loss: 0.004\n",
      "Epoch 400 loss: 0.004\n",
      "Epoch 410 loss: 0.004\n",
      "Epoch 420 loss: 0.004\n",
      "Epoch 430 loss: 0.004\n",
      "Epoch 440 loss: 0.004\n",
      "Epoch 450 loss: 0.004\n",
      "Epoch 460 loss: 0.004\n",
      "Epoch 470 loss: 0.004\n",
      "Epoch 480 loss: 0.003\n",
      "Epoch 490 loss: 0.003\n",
      "Epoch 500 loss: 0.003\n",
      "Epoch 510 loss: 0.003\n",
      "Epoch 520 loss: 0.003\n",
      "Epoch 530 loss: 0.003\n",
      "Epoch 540 loss: 0.003\n",
      "Epoch 550 loss: 0.003\n",
      "Epoch 560 loss: 0.003\n",
      "Epoch 570 loss: 0.003\n",
      "Epoch 580 loss: 0.003\n",
      "Epoch 590 loss: 0.003\n",
      "Epoch 600 loss: 0.003\n",
      "Epoch 610 loss: 0.003\n",
      "Epoch 620 loss: 0.003\n",
      "Epoch 630 loss: 0.003\n",
      "Epoch 640 loss: 0.002\n",
      "Epoch 650 loss: 0.002\n",
      "Epoch 660 loss: 0.002\n",
      "Epoch 670 loss: 0.002\n",
      "Epoch 680 loss: 0.002\n",
      "Epoch 690 loss: 0.002\n",
      "Epoch 700 loss: 0.002\n",
      "Epoch 710 loss: 0.002\n",
      "Epoch 720 loss: 0.002\n",
      "Epoch 730 loss: 0.002\n",
      "Epoch 740 loss: 0.002\n",
      "Epoch 750 loss: 0.002\n",
      "Epoch 760 loss: 0.002\n",
      "Epoch 770 loss: 0.002\n",
      "Epoch 780 loss: 0.002\n",
      "Epoch 790 loss: 0.002\n",
      "Epoch 800 loss: 0.002\n",
      "Epoch 810 loss: 0.002\n",
      "Epoch 820 loss: 0.002\n",
      "Epoch 830 loss: 0.002\n",
      "Epoch 840 loss: 0.002\n",
      "Epoch 850 loss: 0.002\n",
      "Epoch 860 loss: 0.002\n",
      "Epoch 870 loss: 0.002\n",
      "Epoch 880 loss: 0.002\n",
      "Epoch 890 loss: 0.002\n",
      "Epoch 900 loss: 0.002\n",
      "Epoch 910 loss: 0.002\n",
      "Epoch 920 loss: 0.002\n",
      "Epoch 930 loss: 0.002\n",
      "Epoch 940 loss: 0.002\n",
      "Epoch 950 loss: 0.002\n",
      "Epoch 960 loss: 0.002\n",
      "Epoch 970 loss: 0.002\n",
      "Epoch 980 loss: 0.002\n",
      "Epoch 990 loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  # Сигмоидная функция активации: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Производная сигмоиды: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true и y_pred - массивы numpy одинаковой длины.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "  '''\n",
    "  Нейронная сеть с:\n",
    "    - 2 входами\n",
    "    - скрытым слоем с 2 нейронами (h1, h2)\n",
    "    - выходной слой с 1 нейроном (o1)\n",
    "\n",
    "  *** DISCLAIMER ***:\n",
    "  Следующий код простой и обучающий, но НЕ оптимальный.\n",
    "  Код реальных нейронных сетей совсем на него не похож. НЕ копируйте его! \n",
    "  Изучайте и запускайте его, чтобы понять, как работает эта нейронная сеть.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    # Веса\n",
    "    self.w1 = np.random.normal()\n",
    "    self.w2 = np.random.normal()\n",
    "    self.w3 = np.random.normal()\n",
    "    self.w4 = np.random.normal()\n",
    "    self.w5 = np.random.normal()\n",
    "    self.w6 = np.random.normal()\n",
    "\n",
    "    # Пороги\n",
    "    self.b1 = np.random.normal()\n",
    "    self.b2 = np.random.normal()\n",
    "    self.b3 = np.random.normal()\n",
    "\n",
    "  def predict(self, x):\n",
    "    # x is a numpy array with 2 elements.\n",
    "    h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "    h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "    o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "    return o1\n",
    "\n",
    "  def train(self, data, all_y_trues):\n",
    "    '''\n",
    "    - data - массив numpy (n x 2) numpy, n = к-во наблюдений в наборе. \n",
    "    - all_y_trues - массив numpy с n элементами.\n",
    "      Элементы all_y_trues соответствуют наблюдениям в data.\n",
    "    '''\n",
    "    learn_rate = 0.1\n",
    "    epochs = 1000 # сколько раз пройти по всему набору данных \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      for x, y_true in zip(data, all_y_trues):\n",
    "        # --- Прямой проход (эти значения нам понадобятся позже)\n",
    "        sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "        h1 = sigmoid(sum_h1)\n",
    "\n",
    "        sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
    "        h2 = sigmoid(sum_h2)\n",
    "\n",
    "        sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
    "        o1 = sigmoid(sum_o1)\n",
    "        y_pred = o1\n",
    "\n",
    "        # --- Считаем частные производные.\n",
    "        # --- Имена: d_L_d_w1 = \"частная производная L по w1\"\n",
    "        d_L_d_ypred = -2 * (y_true - y_pred)\n",
    "\n",
    "        # Нейрон o1\n",
    "        d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
    "\n",
    "        d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
    "        d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
    "\n",
    "        # Нейрон h1\n",
    "        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
    "        d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
    "\n",
    "        # Нейрон h2\n",
    "        d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
    "        d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
    "\n",
    "        # --- Обновляем веса и пороги\n",
    "        # Нейрон h1\n",
    "        self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "        self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
    "        self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
    "\n",
    "        # Нейрон h2\n",
    "        self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
    "        self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
    "        self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "\n",
    "        # Нейрон o1\n",
    "        self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
    "        self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
    "        self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
    "\n",
    "      # --- Считаем полные потери в конце каждой эпохи\n",
    "      if epoch % 10 == 0:\n",
    "        y_preds = np.apply_along_axis(self.predict, 1, data)\n",
    "        loss = mse_loss(all_y_trues, y_preds)\n",
    "        print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "\n",
    "# Определим набор данных\n",
    "data = np.array([\n",
    "  [-2, -1],  # Алиса\n",
    "  [25, 6],   # Боб\n",
    "  [17, 4],   # Чарли\n",
    "  [-15, -6], # Диана\n",
    "])\n",
    "all_y_trues = np.array([\n",
    "  1, # Алиса\n",
    "  0, # Боб\n",
    "  0, # Чарли\n",
    "  1, # Диана\n",
    "])\n",
    "\n",
    "# Обучаем нашу нейронную сеть!\n",
    "network = OurNeuralNetwork()\n",
    "network.train(data, all_y_trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee79a01",
   "metadata": {},
   "source": [
    "### Проверяем на своих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41c8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_val(height, weight):\n",
    "    \"\"\"\n",
    "    Функция вычисляет индексы для роста и веса.\n",
    "    \n",
    "    :param height: рост,\n",
    "    :param weight: вес,\n",
    "    :return: пересчитанные индексы.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [int(height*2.2-135), int(weight/2.54-66)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6987ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим новый набор данных\n",
    "array_weight_height = np.array([\n",
    "    calc_val(50, 174), # Валентина \n",
    "    calc_val(71, 178), # Виктор\n",
    "    calc_val(68, 185), # Евгений\n",
    "    calc_val(55, 165), # Мила  \n",
    "    calc_val(43, 169), # Анжелина\n",
    "    calc_val(56, 164), # Скарлет \n",
    "])\n",
    "array_gender = np.array([ \n",
    "    1, # Валентина \n",
    "    0, # Виктор\n",
    "    0, # Евгений\n",
    "    1, # Мила  \n",
    "    1, # Анжелина\n",
    "    1, # Скарлет     \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dbb46e",
   "metadata": {},
   "source": [
    "### Метрика accuracy — доля правильных ответов алгоритма\n",
    "$ accuracy = \\frac{TP+TN}{TP+TN+FP+FN} $ \n",
    "\n",
    "где TP - Истинно-положительный (True Positive);  \n",
    "FP - Ложно-положительный (False Positive);  \n",
    "TN - Истинно-отрицательный (True Negative);  \n",
    "FN - Ложно-отрицательный (False Negative).  \n",
    "\n",
    "см. [ссылка](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8#:~:text=%D0%90%D0%BA%D0%BA%D1%83%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C%20(%D0%B0%D0%BD%D0%B3%D0%BB.&text=%D0%98%D0%BD%D1%82%D1%83%D0%B8%D1%82%D0%B8%D0%B2%D0%BD%D0%BE%20%D0%BF%D0%BE%D0%BD%D1%8F%D1%82%D0%BD%D0%BE%D0%B9%2C%20%D0%BE%D1%87%D0%B5%D0%B2%D0%B8%D0%B4%D0%BD%D0%BE%D0%B9%20%D0%B8%20%D0%BF%D0%BE%D1%87%D1%82%D0%B8,N%2BFP%2BFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1489f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(weight_height, gender):\n",
    "    \"\"\"\n",
    "    Функция вычисляет долю правельных ответов.\n",
    "\n",
    "    :param weight_height: массив с весом и ростом,\n",
    "    :param gender: гендер (мужчина-0/женщина-1),\n",
    "    :return: если массивы разной размерности, то -1 или доля правельных ответов.   \n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    if len(array_weight_height) == len(array_gender):\n",
    "        for i in range(len(array_weight_height)):\n",
    "            if network.predict(array_weight_height[i]) >= 0.8 and array_gender[i] == 1:\n",
    "                TP += 1\n",
    "            elif network.predict(array_weight_height[i]) >= 0.8 and array_gender[i] == 0:\n",
    "                FN += 1\n",
    "            elif network.predict(array_weight_height[i]) <= 0.05 and array_gender[i] == 0:\n",
    "                TN += 1\n",
    "            elif network.predict(array_weight_height[i]) <= 0.05 and array_gender[i] == 1:\n",
    "                FP += 1\n",
    "        print(f'{TP = } {TN = } {FP = } {FN = }')\n",
    "        try:\n",
    "            return (TP+TN)/(TP+TN+FP+FN)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe9b4858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 4 TN = 2 FP = 0 FN = 0\n",
      "Доля правильных ответов алгоритма = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Доля правильных ответов алгоритма = {accuracy(array_weight_height, array_gender)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1263334",
   "metadata": {},
   "source": [
    "## Вывод: НС обучившись на тестовых данных, была проверена на собственных данных и показала долю правельных ответов (accuracy) 100%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98846a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7824d94b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa8b969",
   "metadata": {},
   "source": [
    "### Часть 2. Обучите НС mlpclassifier от sklearn.\n",
    "\n",
    "см. [ссылка](https://scikit-learn.ru/1-17-neural-network-models-supervised/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a128d2f",
   "metadata": {},
   "source": [
    "### Проверяем и уствнавливаем последнию версию scikit-learn\n",
    "см. [документация](https://scikit-learn.org/stable/install.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161b5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1af8c03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.4.0\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: c:\\users\\uc201\\anaconda3\\lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: scikit-learn-intelex\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show scikit-learn         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977ff35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(data, all_y_trues)\n",
    "clf.predict(array_weight_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38023bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_gender = array([1, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'{array_gender = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819d28b",
   "metadata": {},
   "source": [
    "## Вывод: НС mlpclassifier от sklearn после обучения на тестовых данных, так же показала 100% результат на собственных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cdc2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
